Vorgehen: 
Zuerst theoretisches Modell entwickeln, indem 8 Teilaugaben von Alessandro 
umgesetzt werden. Ggf bereits in TensorFlow einarbeiten
Dann wirkliche Implementierung beginnen.
    NLP und falls nicht vermeidbar Data Mining, dann daraus ML entwickeln
    Model Assessments jeder implementierung, um die Qualität zu bestimmen 
        (die fuer unser Szenarion hoeher, als die externer Modelle sein sollte)
    Wird ein großer Teil des Algorithmus selbst geschrieben Unit Tests fuer
        im idealfall alle Funktionen

Technologien und Frameworks: 
    ML:
        TensorFlow (tensorflow recommenders)
        Keras als High-Lvl abstraction von TensorFlow, Zeit sparend
        skLearn als Bibliothek
    Training:
        Google Server
        Spacy
    NLP:
        Spacy
        Brat oder besser Prodigy, falls Daten selbst annotiert werden muessen
    Daten:
        sklearn
    Visualisierung:
        matplotlip (Python Bibliothek)
        seaborn (basiert auf matplotlib)
    Validierung/Evaluation:
    (Vergleich:)

Falls weiteres noetig - Machine-Learning Toolbox:
https://amitness.com/toolbox/


TODO:
Experimentieren mit dem leastEffort Modell basierend auf Alessandros Unterlagen
    verschiedene sklearn-Algorithmen ausprobieren
Tensorflow-Einarbeitung
word2vec - 
    preparations\NLP\internal\readme.txt
Beispiel durcharbeiten, z.B.
    https://www.analyticsvidhya.com/blog/2020/08/recommendation-system-k-nearest-neighbors/
Integration mit Server

Vollstaendig abgearbeite Schritte:
 - 

!Installationen und Erklaerungen finden sich in den jeweiligen Ordnern in preparations
